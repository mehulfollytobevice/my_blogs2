<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mehul Jain and Bishal Agrawal">
<meta name="dcterms.date" content="2024-09-01">

<title>Thoughts, Code and Mischief - Unleashing Productivity - How In-House RAG Systems Can Turbocharge Your Data Science Team</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Thoughts, Code and Mischief</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">Hi üëã, I‚Äôm Mehul</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mehulfollytobevice"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Unleashing Productivity - How In-House RAG Systems Can Turbocharge Your Data Science Team</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">markdown</div>
                <div class="quarto-category">data_science</div>
                <div class="quarto-category">NLP</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Mehul Jain and Bishal Agrawal </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 1, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction:</a>
  <ul class="collapse">
  <li><a href="#what-is-a-rag" id="toc-what-is-a-rag" class="nav-link" data-scroll-target="#what-is-a-rag">What is a RAG?</a></li>
  <li><a href="#the-necessity-for-an-in-house-rag-system" id="toc-the-necessity-for-an-in-house-rag-system" class="nav-link" data-scroll-target="#the-necessity-for-an-in-house-rag-system">The Necessity for an In-House RAG System:</a></li>
  <li><a href="#golden-retriever" id="toc-golden-retriever" class="nav-link" data-scroll-target="#golden-retriever">Golden Retriever:</a></li>
  </ul></li>
  <li><a href="#methodology" id="toc-methodology" class="nav-link" data-scroll-target="#methodology">Methodology:</a>
  <ul class="collapse">
  <li><a href="#dataset-and-document-preprocessing" id="toc-dataset-and-document-preprocessing" class="nav-link" data-scroll-target="#dataset-and-document-preprocessing">Dataset and Document Preprocessing:</a></li>
  <li><a href="#vector-embeddings-and-document-retrieval" id="toc-vector-embeddings-and-document-retrieval" class="nav-link" data-scroll-target="#vector-embeddings-and-document-retrieval">Vector Embeddings and Document Retrieval:</a></li>
  <li><a href="#prompting-and-output-generation" id="toc-prompting-and-output-generation" class="nav-link" data-scroll-target="#prompting-and-output-generation">Prompting and Output Generation:</a></li>
  <li><a href="#user-interface" id="toc-user-interface" class="nav-link" data-scroll-target="#user-interface">User Interface:</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion:</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References:</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In today‚Äôs data-driven world, data science teams are the engines powering innovation, driving insights, and enabling informed decision-making across industries. As the complexity and volume of data continue to grow, so does the need for tools that streamline workflows and enhance productivity. Enter the in-house Retrieval-Augmented Generation (RAG) system, a pioneering solution designed to elevate the efficiency of data science teams. Unlike other RAG systems that rely on internet connectivity to fetch data, this system uses pre-downloaded information from key data science libraries, ensuring data privacy and security are maintained.</p>
<p>In this blog post, we‚Äôll explore how an in-house RAG system can leverage documentation from popular data science libraries to boost productivity of data scientists. We‚Äôll delve into its methodology, discuss the dataset it utilizes, examine its evaluation process, explore its user interface, and consider its potential impact on data science teams. Join us as we uncover how this innovative tool can revolutionize data science operations.</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction:</h2>
<p>Imagine you‚Äôre a data scientist working on a crucial project with a tight deadline. You hit a roadblock: a burning question about how to efficiently aggregate data in Pandas. Naturally, you turn to ChatGPT or similar AI services to get quick answers and move forward. These tools have become indispensable for professionals seeking instant solutions to technical queries and coding challenges, helping streamline workflows and accelerate progress. However, while these AI services are immensely beneficial, they also come with significant challenges, particularly around data privacy, data relevance, and integration with proprietary tools. Furthermore, services like ChatGPT often fall short by not providing references alongside their answers. This lack of direct citations can hinder deeper research and verification of solutions, making it challenging to confirm the effectiveness of the advice given.</p>
<p>Enter RAGs!!!</p>
<section id="what-is-a-rag" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-rag">What is a RAG?</h3>
<p>A Retrieval-Augmented Generation (RAG) system is a sophisticated AI tool that combines the capabilities of retrieving specific, relevant information from a predefined database with the generative power to provide coherent, contextually appropriate responses. Unlike standalone language models that depend solely on their training data, RAG systems augment their responses by accessing external sources, making them particularly valuable in technical fields like data science, where accuracy and timeliness of information are crucial. As companies seek more secure and customized solutions, RAG systems, such as those offered by platforms like You.com, are increasingly being recognized as viable alternatives to traditional AI services like ChatGPT.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rad_ds.jpg" class="img-fluid figure-img"></p>
<figcaption>RAG Flowchart</figcaption>
</figure>
</div>
</section>
<section id="the-necessity-for-an-in-house-rag-system" class="level3">
<h3 class="anchored" data-anchor-id="the-necessity-for-an-in-house-rag-system">The Necessity for an In-House RAG System:</h3>
<p>In addition to the absence of citation capabilities, privacy concerns are paramount when using services like ChatGPT. Companies are naturally cautious about sending sensitive data to external servers, such as those managed by OpenAI, due to the risk of data exposure and leakage. This creates a substantial barrier for organizations with strict data privacy policies.</p>
<p>Moreover, there are other challenges associated with using such services for technical queries:</p>
<ul>
<li><strong>Data Freshness and Relevance:</strong> These services may not always provide the most up-to-date information, as they rely on static datasets that can overlook the latest updates in technical documentation and library features.</li>
<li><strong>Complex Query Handling:</strong> While effective for general inquiries, these tools can struggle with complex or highly specific technical queries, often producing generic responses that may not fully address the user‚Äôs needs.</li>
<li><strong>Integration with Proprietary Tools:</strong> Public AI services cannot accommodate the unique requirements of proprietary data science packages, limiting their effectiveness in customized workflows.</li>
</ul>
</section>
<section id="golden-retriever" class="level3">
<h3 class="anchored" data-anchor-id="golden-retriever">Golden Retriever:</h3>
<p>In this blog post, we will explore the importance and various aspects of an in-house Retrieval-Augmented Generation (RAG) system through the implementation of the Golden Retriever project. Built to meet the unique needs of data science teams, Golden Retriever works primarily on a local server, meaning it doesn‚Äôt need internet access to function. This ensures strong data privacy. The system uses pre-downloaded data from essential libraries to deliver accurate, personalized, and reference-rich responses. With its easy-to-use Streamlit interface and modular design, Golden Retriever is adaptable and scalable, making it an effective tool for maintaining up-to-date information and integrating proprietary tools.</p>
</section>
</section>
<section id="methodology" class="level2">
<h2 class="anchored" data-anchor-id="methodology">Methodology:</h2>
<p>Our in-house Retrieval-Augmented Generation (RAG) system employs a sophisticated methodology to deliver accurate and context-rich responses for data science teams. Here‚Äôs a brief overview of our approach:</p>
<ol type="1">
<li><p><strong>Document Preprocessing</strong>: We extract and clean data from popular data science libraries like <code>Pandas</code>,<code>NumPy</code>, and <code>Scikit-learn</code> using tools such as BSHTMLLoader and BeautifulSoup. This refined content is then stored as pickle files for efficient processing.</p></li>
<li><p><strong>Embedding and Vector Storage</strong>: The preprocessed documents are chunked and embedded using the <code>gte-large-en-v1.5</code> model. These embeddings are stored in ChromaDB vector databases, enabling rapid and accurate information retrieval.</p></li>
<li><p><strong>Advanced Query Processing</strong>: Our system utilizes intelligent query processing techniques to understand complex technical queries and retrieve relevant documents.</p></li>
<li><p><strong>Output Generation</strong>: We leverage the powerful <code>llama-3.1-70b</code> generative model to produce high-quality, tailored responses. The system combines retrieved documents with a prompt to generate comprehensive answers while also providing relevant document links as references.</p></li>
<li><p><strong>Offline Functionality</strong>: Designed to operate without internet connectivity, our RAG system is ideal for secure or isolated environments, ensuring data privacy and accessibility.</p></li>
</ol>
<section id="dataset-and-document-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="dataset-and-document-preprocessing">Dataset and Document Preprocessing:</h3>
<p>This project utilizes a comprehensive dataset derived from the documentation of three widely-used data science libraries: Pandas, Scikit-learn, and NumPy. To create this dataset, we employ a fairly straightforward data acquisition process. Using the Python requests module, we download all the zipped documentation files for each library from their respective official sources. These compressed files are then systematically extracted, and the relevant text content is saved into a dedicated documents folder. This approach ensures that the RAG system has access to the most up-to-date and accurate information from these essential libraries. By incorporating documentation from these diverse sources, the system can provide comprehensive and context-rich responses to a wide range of data science queries, all while operating in an offline environment.</p>
<p>The document preprocessing stage is a crucial step in our RAG system‚Äôs pipeline. After downloading the documentation files, we employ a sophisticated approach to extract and refine the content of the input files. Using the <code>BSHTMLLoader</code> from Langchain, we parse the HTML files from the documentation. This loader efficiently extracts the relevant text content while preserving the structure. To further clean and optimize the extracted data, we utilize <code>BeautifulSoup</code>, which helps remove unnecessary HTML tags and formatting. This dual-layer approach ensures comprehensive content coverage while enabling detailed indexing. Finally, we store the preprocessed documents as pickle files, which allows for efficient storage and quick retrieval in subsequent stages of the RAG pipeline.</p>
<p>This meticulous preprocessing ensures that our system works with clean, well-structured data, ultimately enhancing the quality and relevance of the generated responses.</p>
</section>
<section id="vector-embeddings-and-document-retrieval" class="level3">
<h3 class="anchored" data-anchor-id="vector-embeddings-and-document-retrieval">Vector Embeddings and Document Retrieval:</h3>
<p>The next step in our RAG pipeline is to transform the preprocessed documents into searchable vector representations. We begin by loading the previously saved pickle files, which contain cleaned and structured content from popular data science libraries.</p>
<p>For generating embeddings, we leverage the <code>gte-large-en-v1.5</code> model from Hugging Face, chosen for its superior ability to capture semantic relationships within technical documentation. The loaded documents undergo further processing using <code>RecursiveCharacterTextSplitter</code>, creating a dual-layer structure of parent documents (2000 characters with 200-character overlap) and child documents (500 characters with 50-character overlap). This approach ensures extensive content coverage while enabling detailed indexing.The <code>RecursiveCharacterTextSplitter</code> is particularly advantageous for our RAG system as it intelligently splits text based on character count while respecting the inherent structure of the document. It recursively splits on a list of characters (like ‚Äú‚Äù, ‚Äú‚Äù, ‚Äù ‚Äú,‚Äù‚Äú) which helps maintain the semantic coherence of the content.</p>
<p>To facilitate efficient similarity searching, we implement <code>ParentDocumentRetriever</code>. It enables us to maintain broader context through parent documents while allowing for granular searches in child documents. This takes advantage of the hierarchical structure of our chunked documents, allowing for rapid and accurate retrieval of relevant information. The generated embeddings are then stored in <code>ChromaDB</code> vector database, enabling fast retrieval during query processing.</p>
<p>This carefully designed embedding and retrieval process forms the backbone of our RAG system. By transforming our extensive documentation into a searchable vector space, we ensure quick access to contextually relevant information that the LLM uses to generate an answer for the user query.</p>
</section>
<section id="prompting-and-output-generation" class="level3">
<h3 class="anchored" data-anchor-id="prompting-and-output-generation">Prompting and Output Generation:</h3>
<p>The prompting and output generation process in our RAG system is a sophisticated orchestration of several key components. At the heart of this process is a custom memory system that stores conversation history using a simple yet effective list structure. This way the system is able to maintain context across multiple interactions without relying on external databases, ensuring seamless and coherent conversations even in offline environments.</p>
<p>The system‚Äôs document retrieval process is powered by the <code>ParentDocumentRetriever</code>, which performs a similarity search to fetch the top 4 most relevant documents. After searching for the relevant information, the system creates a customized prompt which is fed to the LLM.</p>
<p>A carefully crafted prompt template serves as the blueprint for response generation. This template ingeniously combines the user‚Äôs query, conversation history, and retrieved documents, providing a comprehensive context to the language model. By structuring the input in this way, we guide the model to produce responses that are not only accurate but also contextually appropriate and coherent with previous interactions.</p>
<p>For the actual response generation, we leverage the power of the <strong>Llama 3.1 70B model</strong> through the <strong>Groq API</strong>. This API allows us to harness state-of-the-art language models while benefiting from cloud-based processing speed, crucial for maintaining system responsiveness. The generated output then undergoes custom post-processing to include relevant document links which the users can reference.</p>
<p>The system‚Äôs conversational loop ties all these elements together, enabling multi-turn interactions that maintain context throughout the conversation. This feature is particularly valuable for data scientists dealing with complex queries that often require follow-up questions or clarifications.</p>
</section>
<section id="user-interface" class="level3">
<h3 class="anchored" data-anchor-id="user-interface">User Interface:</h3>
<p>The Golden Retriever RAG system features a user-friendly interface built using Streamlit, providing an intuitive way for users to interact with the powerful RAG capabilities. This interface seamlessly integrates various components of the system, offering a clean, chat-like experience where users can input queries and receive detailed responses.</p>
<p>The Streamlit app first loads all the pre-processed documents and embeddings, setting up the RAG pipeline including the ParentDocumentRetriever and language model. As users interact with the system, their queries are processed through this pipeline, retrieving relevant documents and generating responses using the Llama 3.1 70B model via the Groq API. The interface displays these results along with reference links, ensuring traceability to source documentation.</p>
<p>A key feature of the interface is its ability to manage conversation history, allowing for coherent multi-turn interactions. By presenting sophisticated RAG technology through a simple, accessible interface, the Golden Retriever system enhances workflow efficiency for data scientists.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rag_ui.png" class="img-fluid figure-img"></p>
<figcaption>Golden Retriever Streamlit User Interface</figcaption>
</figure>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion:</h2>
<p>Imagine Sarah, a data scientist who frequently finds herself scouring Pandas documentation to refresh her memory on data frame aggregation techniques. With the Golden Retriever RAG system at her fingertips, Sarah can quickly access accurate, context-aware information without leaving her secure work environment. Instead of spending precious time navigating through multiple web pages, she can simply ask the system, ‚ÄúHow do I aggregate data frames by multiple columns in Pandas?‚Äù and receive a concise, tailored response with relevant code snippets and documentation links.</p>
<p>Now consider Alex, a junior data scientist tasked with building his first sentiment analysis system using the company‚Äôs proprietary NLP package. As he delves into this complex project, he encounters a myriad of questions: ‚ÄúWhat‚Äôs the best way to pre-process text data for sentiment analysis?‚Äù ‚ÄúHow do I handle imbalanced classes in my sentiment dataset?‚Äù ‚ÄúWhich machine learning models are most effective for sentiment classification?‚Äù With each query, the Golden Retriever system provides Alex with comprehensive answers, drawing from its vast knowledge base of Scikit-learn, NLTK, and the in-house libraries. The system not only offers explanations but also suggests best practices, potential pitfalls to avoid, and even code examples to jumpstart his implementation.</p>
<p>By leveraging the RAG system, both Sarah and Alex can work more efficiently, spending less time searching for information and more time applying their expertise to solve complex data science challenges.</p>
<p>In conclusion, our in-house Retrieval-Augmented Generation (RAG) system, Golden Retriever, represents a significant leap forward in empowering data science teams with efficient, accurate, and context-aware information retrieval. By leveraging advanced technologies such as state-of-the-art embedding models, intelligent document preprocessing, and powerful language models, we‚Äôve created a system that operates seamlessly in offline environments while providing high-quality responses.</p>
<p>Check out the full project <a href="https://github.com/mehulfollytobevice/golden-retriever">here</a>.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References:</h2>
<ul>
<li><a href="https://github.com/mehulfollytobevice/golden-retriever">Github Repo</a></li>
<li><a href="https://www.langchain.com/">Langchain Website</a></li>
<li><a href="https://console.groq.com/docs/quickstart">Groq API Documentation</a></li>
<li><a href="https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/">Recursive Character Splitting</a></li>
<li><a href="https://www.trychroma.com/">Chroma DB</a></li>
<li><a href="https://huggingface.co/spaces/mteb/leaderboard">Model Comparison with MTEB leaderboard</a></li>
<li><a href="https://arxiv.org/abs/2302.13971">LLaMA: Open and Efficient Foundation Language Models</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/mehulfollytobevice\.github\.io\/my_blogs2\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>